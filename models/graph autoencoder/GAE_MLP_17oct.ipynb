{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37f84e2-7683-44c4-8c8d-39f688f08804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to 'processed_graph_data.pt'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import numpy as np\n",
    "\n",
    "# Load the labeled and unlabeled data\n",
    "labeled_data = pd.read_csv('3k_labeled_extracted.csv')\n",
    "unlabeled_data = pd.read_csv('6k_unlabeled_extracted.csv')\n",
    "\n",
    "# Drop the 'text_' column as it's not required\n",
    "labeled_data = labeled_data.drop(columns=['text_'])\n",
    "unlabeled_data = unlabeled_data.drop(columns=['text_'])\n",
    "\n",
    "# Separate features and labels\n",
    "X_labeled = labeled_data.drop(columns=['label']).values\n",
    "y_labeled = labeled_data['label'].values\n",
    "X_unlabeled = unlabeled_data.values\n",
    "\n",
    "# Normalize the features using Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_labeled_scaled = scaler.fit_transform(X_labeled)\n",
    "X_unlabeled_scaled = scaler.transform(X_unlabeled)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_labeled_tensor = torch.tensor(X_labeled_scaled, dtype=torch.float)\n",
    "y_labeled_tensor = torch.tensor(y_labeled, dtype=torch.long)\n",
    "X_unlabeled_tensor = torch.tensor(X_unlabeled_scaled, dtype=torch.float)\n",
    "\n",
    "# Compute cosine similarity between all reviews\n",
    "similarity_matrix = cosine_similarity(np.vstack([X_labeled_scaled, X_unlabeled_scaled]))\n",
    "\n",
    "# Create an adjacency matrix where high similarity is considered an edge\n",
    "threshold = 0.7  # Adjust threshold for graph sparsity\n",
    "adjacency_matrix = (similarity_matrix > threshold).astype(int)\n",
    "\n",
    "# Convert adjacency matrix to edge index format for PyTorch Geometric\n",
    "edge_index = dense_to_sparse(torch.tensor(adjacency_matrix, dtype=torch.float))[0]\n",
    "\n",
    "# Prepare PyTorch Geometric Data\n",
    "features = torch.cat([X_labeled_tensor, X_unlabeled_tensor], dim=0)\n",
    "data = Data(x=features, edge_index=edge_index)\n",
    "\n",
    "# Saving the processed data\n",
    "torch.save({\n",
    "    'features': features,\n",
    "    'edge_index': edge_index,\n",
    "    'labels': y_labeled_tensor\n",
    "}, 'processed_graph_data.pt')\n",
    "\n",
    "print(\"Processed data saved to 'processed_graph_data.pt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37775f1e-a871-44a1-8f26-fd6b5ae2657e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to 'graph_autoencoder_model.pt'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GraphAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphAutoencoder, self).__init__()\n",
    "        self.encoder = GCNConv(in_channels, hidden_channels)\n",
    "        self.decoder = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Encoder: learn low-dimensional embeddings\n",
    "        encoded = F.relu(self.encoder(x, edge_index))\n",
    "        # Decoder: reconstruct from embeddings\n",
    "        decoded = self.decoder(encoded, edge_index)\n",
    "        return decoded, encoded\n",
    "\n",
    "# Model parameters\n",
    "in_channels = features.size(1)\n",
    "hidden_channels = 64\n",
    "out_channels = in_channels\n",
    "\n",
    "# Initialize the GAE model\n",
    "gae_model = GraphAutoencoder(in_channels, hidden_channels, out_channels)\n",
    "optimizer = torch.optim.Adam(gae_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Saving the model state\n",
    "torch.save(gae_model.state_dict(), 'graph_autoencoder_model.pt')\n",
    "print(\"Model state saved to 'graph_autoencoder_model.pt'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69b64407-5c91-4c31-83f7-19eceb2b6040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.1279940605163574\n",
      "Trained model state saved to 'graph_autoencoder_model_trained.pt'.\n"
     ]
    }
   ],
   "source": [
    "def train_gae(data, epochs=1):\n",
    "    gae_model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        decoded, encoded = gae_model(data.x, data.edge_index)\n",
    "        \n",
    "        # Reconstruction loss (MSE between original and decoded features)\n",
    "        loss = F.mse_loss(decoded, data.x)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "    # Save the model state after training\n",
    "    torch.save(gae_model.state_dict(), 'graph_autoencoder_model_trained.pt')\n",
    "    print(\"Trained model state saved to 'graph_autoencoder_model_trained.pt'.\")\n",
    "\n",
    "# Train the Graph Autoencoder\n",
    "train_gae(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a631ba6-977a-49ac-9248-adec17784e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Neural Network...\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84      1516\n",
      "           1       0.85      0.82      0.83      1484\n",
      "\n",
      "    accuracy                           0.84      3000\n",
      "   macro avg       0.84      0.84      0.84      3000\n",
      "weighted avg       0.84      0.84      0.84      3000\n",
      "\n",
      "Accuracy: 83.60%\n",
      "Unlabeled data with predicted labels saved to '5pm_unlabeled_data_with_predictions.csv'.\n",
      "\n",
      "Head of the new predictions:\n",
      "   rating  Positive Score  Negative Score  Neutral Score  Compound Score  \\\n",
      "0     3.0           0.000           0.000          1.000          0.0000   \n",
      "1     1.0           0.073           0.253          0.674         -0.8685   \n",
      "2     5.0           0.598           0.000          0.402          0.9246   \n",
      "3     1.0           0.158           0.094          0.747          0.7500   \n",
      "4     5.0           0.203           0.054          0.743          0.9287   \n",
      "\n",
      "   Review Length  Noun Count  Verb Count  Adjective Count  Joy Score  \\\n",
      "0              1           1           0                0      0.000   \n",
      "1             42          12           9                5      0.073   \n",
      "2             14           5           2                2      0.598   \n",
      "3            140          45          27               11      0.158   \n",
      "4             79          22          19                5      0.203   \n",
      "\n",
      "   Sadness Score  BERT Component 1  BERT Component 2  BERT Component 3  \\\n",
      "0          0.000         -5.235278         -0.133021         -0.114847   \n",
      "1          0.253          4.228276         -0.769990         -0.247665   \n",
      "2          0.000          3.033373         -2.084538          0.154726   \n",
      "3          0.094          3.802375         -0.908699          0.063371   \n",
      "4          0.054          4.029655         -0.985872         -0.374943   \n",
      "\n",
      "   predicted_label  \n",
      "0                1  \n",
      "1                1  \n",
      "2                0  \n",
      "3                0  \n",
      "4                0  \n",
      "\n",
      "Tail of the new predictions:\n",
      "      rating  Positive Score  Negative Score  Neutral Score  Compound Score  \\\n",
      "6105     5.0           0.290           0.000          0.710          0.8479   \n",
      "6106     5.0           0.000           0.000          1.000          0.0000   \n",
      "6107     3.0           0.000           0.000          1.000          0.0000   \n",
      "6108     3.0           0.000           0.305          0.695         -0.7845   \n",
      "6109     4.0           0.444           0.000          0.556          0.7906   \n",
      "\n",
      "      Review Length  Noun Count  Verb Count  Adjective Count  Joy Score  \\\n",
      "6105             30           6           7                3      0.290   \n",
      "6106             13           3           2                3      0.000   \n",
      "6107              4           1           1                1      0.000   \n",
      "6108             21           4           3                3      0.000   \n",
      "6109             14           5           2                3      0.444   \n",
      "\n",
      "      Sadness Score  BERT Component 1  BERT Component 2  BERT Component 3  \\\n",
      "6105          0.000          3.098872         -0.590102         -0.120734   \n",
      "6106          0.000          1.779027         -0.017244         -0.597282   \n",
      "6107          0.000         -0.153303          0.286419         -0.053119   \n",
      "6108          0.305          1.389424         -0.159722         -0.058907   \n",
      "6109          0.000          1.642842         -0.597820         -0.500441   \n",
      "\n",
      "      predicted_label  \n",
      "6105                0  \n",
      "6106                1  \n",
      "6107                1  \n",
      "6108                1  \n",
      "6109                0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Custom function to extract embeddings\n",
    "def extract_embeddings(model: torch.nn.Module, data: Data) -> np.ndarray:\n",
    "    \"\"\"Extract embeddings from the graph autoencoder model.\"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        _, encoded_features = model(data.x, data.edge_index)\n",
    "    return encoded_features.numpy()\n",
    "\n",
    "# Custom function to evaluate a classifier\n",
    "def evaluate_classifier(classifier, X_train: np.ndarray, y_train: np.ndarray) -> None:\n",
    "    \"\"\"Evaluate the trained model and print classification report.\"\"\"\n",
    "    y_pred = classifier.predict(X_train)  # Predict on the labeled training data\n",
    "    report = classification_report(y_train, y_pred, output_dict=True)\n",
    "    accuracy = report['accuracy'] * 100  # Convert to percentage\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Custom function to predict unlabeled data\n",
    "def predict_unlabeled(classifier, encoded_features: np.ndarray, num_labeled: int) -> np.ndarray:\n",
    "    \"\"\"Predict labels for unlabeled data using the trained classifier.\"\"\"\n",
    "    X_unlabeled_features = encoded_features[num_labeled:]  # Unlabeled features\n",
    "    return classifier.predict(X_unlabeled_features)\n",
    "\n",
    "# Custom function to save predictions\n",
    "def save_predictions(unlabeled_data: pd.DataFrame, predictions: np.ndarray, filename: str) -> None:\n",
    "    \"\"\"Add predicted labels to the unlabeled data and save to a CSV file.\"\"\"\n",
    "    unlabeled_data['predicted_label'] = predictions\n",
    "    unlabeled_data.to_csv(filename, index=False)\n",
    "    print(f\"Unlabeled data with predicted labels saved to '{filename}'.\")\n",
    "\n",
    "# Classifier training and evaluation function\n",
    "def train_and_evaluate(classifier, X_train: np.ndarray, y_train: np.ndarray, model_name: str) -> None:\n",
    "    \"\"\"Train the classifier and evaluate it.\"\"\"\n",
    "    classifier.fit(X_train, y_train)\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    return evaluate_classifier(classifier, X_train, y_train)\n",
    "\n",
    "def main():\n",
    "    # Load your data here (assuming data and labeled tensors are already prepared)\n",
    "    # Example: data = ...\n",
    "\n",
    "    # Step 1: Extract embeddings\n",
    "    encoded_features = extract_embeddings(gae_model, data)\n",
    "\n",
    "    # Step 2: Train the Neural Network model\n",
    "    num_labeled = X_labeled_tensor.size(0)  # Get number of labeled samples\n",
    "    X_train = encoded_features[:num_labeled]  # Labeled features\n",
    "    y_train = y_labeled_tensor.numpy()  # Labeled targets\n",
    "\n",
    "    # Initialize Neural Network Classifier\n",
    "    neural_net = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1500, random_state=42)\n",
    "\n",
    "    # Train and evaluate the Neural Network classifier\n",
    "    train_and_evaluate(neural_net, X_train, y_train, \"Neural Network\")\n",
    "\n",
    "    # Step 4: Predict on the unlabeled data using the trained neural network\n",
    "    predicted_labels = predict_unlabeled(neural_net, encoded_features, num_labeled)\n",
    "\n",
    "    # Step 5: Save the updated unlabeled data with predictions\n",
    "    save_predictions(unlabeled_data, predicted_labels, '5pm_unlabeled_data_with_predictions.csv')\n",
    "\n",
    "    # Print head and tail of the new predictions without extra column lines\n",
    "    print(\"\\nHead of the new predictions:\")\n",
    "    print(unlabeled_data.head())  # Display the first few rows\n",
    "\n",
    "    print(\"\\nTail of the new predictions:\")\n",
    "    print(unlabeled_data.tail())  # Display the last few rows\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
